# Relation Radar（关系雷达）产品需求文档（PRD）

版本：v0.2  
作者：自动生成（基于多轮讨论）  
目标周期：原型 1–2 周，v0.x 完整版约 1 个月

---

## 1. 产品概述

### 1.1 一句话定位

Relation Radar 是一个本地优先的 AI 关系助手，把每个朋友当作可以持续更新的“活数据库”，帮助用户记录事实、理解情绪、避免踩雷，并在聚会、送礼、和解等场景给出有根据的建议。

### 1.2 核心理念

- 用户只负责「输入事实」：手动记录、聊天记录截图（OCR 文本）、语音转写内容。
- 系统负责「抽取 & 推理」：结构化存储、RAG 检索、本地小模型 +（可选）远端大模型联合推理。
- 重点帮助用户“读空气”，而不是监视他人或自动收集隐私。

### 1.3 隐私原则

- 默认全本地：所有数据（原始文本、结构化记录、向量索引）都保存在本地设备。
- 通过 MCP server，把本地数据以“脱敏摘要 + 受控工具接口”的形式暴露给远端大模型；远端调用是可选增强模式。
- 所有 AI 回答须带有类似提示：“以上基于你记录的信息，仅供参考”，强调不保证客观真实。

### 1.4 典型使用场景

- 聚会前：  
  “今晚跟猫和阿 B 吃饭，去哪比较合适？”→ 结合饮食偏好、环境喜好、最近情绪，给出餐厅风格和注意事项。
- 生日前：  
  “猫生日送什么？”→ 基于历史记录中的偏好和忌讳，给出 1–3 个礼物建议及理由。
- 关系维护：  
  “最近我冷落了谁？”→ 基于长时间未联系事件、互动频率等，推荐需要主动联系的人。
- 冲突规避：  
  “A 和 C 适合同桌吗？”→ 基于冲突/矛盾记录，提示避免同桌或敏感话题。

---

## 2. 用户与价值

### 2.1 目标用户

- 社交关系较多，需要记住各种偏好/事件/雷区的个人。
- 重视隐私，希望数据完全掌握在自己手中的用户。
- 有一定技术基础的早期用户（能接受本地部署、模型下载），未来再扩展到普通手机 App 用户。

### 2.2 用户痛点

- 记不住每个人的小细节：喜欢什么、讨厌什么、哪些话题是雷区。
- 传统备忘录工具只提供静态记录，无法做情境化建议或多人的平衡。
- 对云端 AI 不完全信任，敏感关系数据不愿上传。

### 2.3 核心价值

- 降低人际关系维护的心智负担：把“人情世故记忆”交给一个本地 AI 助手。
- 在重要节点（生日、聚会、冲突后和解等）提供有依据、可解释的建议。
- 保持隐私可控：默认本地运行，远端增强模式完全由用户选择开启。

---

## 3. 使用范围与模式

### 3.1 功能范围（v0.x）

- 记录：Person / Event / Relationship / 自定义子表（如 Workout）。
- 数据摄入：  
  - 手动文本录入。  
  - 聊天截图 → OCR → 文本。  
  - 语音录音 → Whisper → 文本。  
- 信息抽取：从文本中抽取人物、时间、事件类型、情绪、偏好/忌讳等结构化字段。
- 本地 RAG 问答：基于 SQLite + 向量库的检索 + LLM 回答。
- 多人综合分析：如“今天和谁健身更合适？”、“今晚猫和阿 B 一起吃什么比较好？”。
- 提醒：生日 / 长时间未联系 / 情绪连续偏负面等自动提醒。
- 浏览界面：  
  - “一人一本笔记本”的可视化界面。  
  - 按时间轴和标签快速过滤查看某个朋友的所有记录。

### 3.2 隐私模式

1. 本地模式（默认）  
   - 所有推理使用本地小模型/本地大模型。  
   - 不访问远端大模型，不上传任何数据。
2. 混合模式（可选）  
   - 远端大模型通过 MCP server 调用受控工具（如 `search_events`、`get_person_summary`）。  
   - 只接收脱敏摘要/事实，不直接访问原始全量文本。
3. 云增强模式（进阶）  
   - 用户明示同意后，可将少量脱敏样本发给远端大模型，作为“教师模型”生成高质量答案，存为本地小模型微调数据。  
   - 仍不鼓励上传完整原始记录。

### 3.3 平台与设备策略

- 第一阶段：桌面优先  
  - 优先开发“电脑端本地后端 + Web/桌面 UI”，打牢底层数据结构、RAG、模型调用逻辑。  
  - 后端采用本地 HTTP API（如 FastAPI），未来可直接被手机 App 复用。
- 第二阶段：手机作为“遥控器”  
  - 家用电脑/NAS 上运行 Relation Radar 后端。  
  - iOS/Android App 在同一局域网通过 HTTP 调用后台接口，手机主要负责界面和轻量逻辑。
- 第三阶段：手机独立模式（更长远）  
  - 在手机端内置轻量后端和小模型，实现离线录入、查询和基础建议。  
  - 复杂推理仍可通过 MCP/局域网连接家用服务器或云端。

---

## 4. 核心功能需求

### 4.1 数据结构与录入

#### 4.1.1 数据模型

- **Person（朋友）**  
  - `id`：主键。  
  - `name`：姓名（必填）。  
  - `nickname`：昵称（选填）。  
  - `birthday`：生日（可选）。  
  - `gender`：性别（可选）。  
  - `tags`：标签数组（如“同事”“健身”“爱猫”“怕生”等）。  
  - `notes`：自由备注。  

- **Event（事件）**  
  - `id`：主键。  
  - `person_ids`：参与人的 id 列表（支持多个人）。  
  - `occurred_at`：事件发生时间（标准时间戳）。  
  - `raw_time_text`：原始时间描述（如“昨晚”“去年冬天”）。  
  - `event_type`：事件类型（聊天/会面/冲突/礼物/健身/其他）。  
  - `summary`：事件简要摘要（AI 或人工生成）。  
  - `raw_text`：原始文本（剪贴/转写/手写），加密存储。  
  - `emotion`：情绪/状态描述（如“压力大”“很开心”“疲惫”）。  
  - `preferences`：偏好信息列表（如“喜欢安静的环境”“怕热”“喜欢猫”）。  
  - `taboos`：忌讳/雷区信息列表（如“不喜欢闪光耳钉”“忌辛辣”）。  
  - `tags`：事件标签（如“健身”“生日”“送礼”“聚会”“工作”等）。  
  - `embedding_id`：向量库文档 id（与向量库关联）。  

- **Relationship（关系）**  
  - `id`：主键。  
  - `person_a_id` / `person_b_id`：两个人的 id。  
  - `score`：关系指数（0–1）。  
  - `relation_type`：关系类型（如“朋友”“同事”“家人”等）。  
  - `description`：关系描述（如“都爱宠物，上次吵架已和好”）。  

- **子表（示例：Workout）**  
  - `id`、`person_id`、`date`、`exercise`、`weight`、`reps`、`heart_rate`、`notes` 等。  
  - 子表设计保持可插拔：可扩展 Shopping、ChatSummary 等。

#### 4.1.2 录入通道与流水线

- **手动文本录入**  
  - UI 表单或 CLI 录入原始文本，可关联一个或多个 Person。  
  - 文本提交后走统一“信息抽取链”，自动生成 Event 及子表记录。

- **聊天截图**  
  - 上传截图文件。  
  - 本地 OCR（Tesseract/PaddleOCR）提取文字。  
  - 提示用户确认/修订关键文本。  
  - 再走信息抽取链生成 Event。

- **语音录音**  
  - 导入音频或在应用内录音。  
  - 本地 Whisper ASR 转文字。  
  - 再走信息抽取链生成 Event。

- **统一信息抽取流水线**  
  1. 原始文本 → 送入本地小模型（1–3B）+ 专用 prompt 做信息抽取。  
  2. 模型输出 JSON 数组，每个元素对应一个事件对象（人物列表、时间、事件类型、情绪、偏好/忌讳等）。  
  3. 应用将事件写入 SQLite 和向量库，同时保留原始文本加密存档。  

- **双层存储设计**  
  - 原始层：原始文本/转写全文，用于未来重新抽取或更复杂分析（加密保存）。  
  - 结构化层：用于查询、RAG 和可视化浏览的核心事实（Event/Relationship/子表），也是 MCP 暴露给远端模型时的主要来源。

### 4.2 信息抽取（本地小模型）

- 目标：将原始文本转换为结构化事件列表。  
- 输入：原始文本（手动/截图 OCR/语音转写）。  
- 输出：JSON 数组，每个对象包含：人物、时间、事件类型、摘要、情绪、偏好、忌讳、标签等。  
- 约束：  
  - 不得凭空添加文本中不存在的信息。  
  - 提取不到事件时返回空数组。  
  - 保持输出结构稳定，方便程序解析与单元测试。  

### 4.3 RAG 问答

- **检索流程**  
  1. 用户输入自然语言问题。  
  2. 使用本地 embedding 模型将问题向量化。  
  3. 根据问题和用户选择做元数据过滤：  
     - `person_id in [...]`  
     - 时间范围过滤（如“近三个月”）。  
     - 标签/事件类型过滤（如只看“健身”“送礼”“冲突”）。  
  4. 在过滤后的候选集中做向量检索，取 `top_k` 条相关片段（默认 10，可配置）。  
  5. 把片段格式化为文本 `context`，连同 `question` 一起送入 LLM。  

- **回答要求**  
  - 回答必须完全基于 `context` 提供的记录片段，不能凭空幻想。  
  - 片段不足以回答时，应明确说明“根据当前记录无法确定”，并建议用户补充某类记录。  
  - 回答风格：简洁自然中文，亲切但不过度亲密；在适当处引用具体事件（时间/场景）作为证据。  
  - 所有回答结尾附加提示：“以上基于你记录的信息，仅供参考。”  

- **本地 vs 远端**  
  - 简单问答（单人、短问题）优先使用本地模型。  
  - 多人复杂问题或长上下文需求，可选用远端大模型（通过 MCP server 获取片段）。

### 4.4 多人综合分析与建议

- **场景例子**  
  - 聚餐安排：“今晚和猫、阿 B 吃饭，去哪比较合适？”  
  - 活动搭子：“今天约谁去健身比较合适？”  
  - 冲突规避：“A 和 C 适合一起参加这次聚会吗？需要注意什么？”  

- **输入组成**  
  - 用户问题。  
  - 相关人物画像摘要（每人的偏好、忌讳、近期情绪等）。  
  - 多人相关的事件片段（向量检索 + 元数据过滤）。  

- **输出结构**  
  - 总体建议：活动/地点/搭配方案。  
  - 分人物说明：每个人为什么这样安排（基于哪些记录）。  
  - 雷区提示：需要避免的组合、话题或环境。  
  - 结尾提醒：建议基于现有记录，不一定完整。  

### 4.5 “一人一本笔记本”浏览界面

- **目标**：录入数据不仅服务 AI，也要让用户自己能轻松按人、按时间、按标签浏览记录。

- **界面结构（概念设计）**  
  - 左侧：朋友列表  
    - 按姓名排序、按标签分组，支持搜索。  
  - 中间：当前朋友的“笔记本”  
    - 顶部：头像/标识 + 姓名 + 标签 + 一句画像总结（由 AI 生成）。  
    - 下方：事件时间线（Timeline）  
      - 按时间倒序显示事件卡片，可按时间范围过滤（近一周/近三个月/自定义）。  
      - 顶部有标签筛选（健身/礼物/聊天/冲突等）。  
      - 每条卡片可展开，显示原始文本片段 + 结构化信息（情绪、偏好、忌讳等）。  
  - 右侧：AI 区域（可选）  
    - 针对当前朋友的问答框：“关于 X，你想问什么？”  
    - 提供模板问题（“最近状态如何？”“送礼建议？”“最近有没有雷区？”）。

- **查询能力**  
  - 按人 + 时间：`person_id + occurred_at` 时间线查询。  
  - 按人 + 标签：`person_id + tags` 过滤。  
  - 全文搜索：按关键词搜索某人的事件或全局事件。

### 4.6 提醒与反馈

- **提醒**  
  - 生日/纪念日：根据 Person 和 Event 中日期字段，提前 N 天发出提醒。  
  - 长时间未联系：如某 Person 在最近 N 天没有新事件记录，提醒适当联系。  
  - 情绪型提醒：某人近期多条事件情绪偏负面，提示给予关心或放缓节奏。  

- **反馈机制**  
  - 每次 AI 回答，用户可以标记：准确 / 一般 / 不准 / 有风险。  
  - 记录用户反馈，用于未来微调本地小模型或调整提示词模板。

---

## 5. 技术架构与要点

### 5.1 总体架构

- Backend Core（本地核心）  
  - SQLite 数据库 + schema。  
  - 事件/朋友/关系 CRUD 和业务逻辑。  
  - ingest 流水线（手动/截图/语音 → 文本 → 抽取 → 入库）。  
  - 提醒任务调度。  
- RAG 子系统  
  - 本地 embedding 模型（384–512 维向量）。  
  - 向量库（Chroma/FAISS/SQLite+向量字段）。  
  - 检索器（支持按人/时间/标签过滤；支持“多人的 union 候选集 + 向量检索”）。  
- LLM Engine  
  - 在 `backend/llm` 中定义统一的 Chat/Completion 抽象接口，对上层屏蔽模型来源。  
  - 本地小模型（1–3B），做信息抽取、基础问答。  
  - 桌面本地大模型（如 Qwen2-7B），做复杂推理（PC）。  
  - 远端大模型（云端），通过 MCP server 工具调度。  
- MCP Server（本地）  
  - 把本地数据能力封装为工具接口：`search_events`、`get_person_summary`、`log_feedback` 等。  
  - 作为远端模型访问本地数据的“防火墙 + API 网关”。  
- 前端  
  - v0.x：Web 界面（如 React/Vue/Streamlit）+ CLI。  
  - 未来：iOS/Android App，通过 HTTP API 或特定 SDK 调用后端。

### 5.2 Prompt & LangChain 设计

- 主要任务拆分为 4 类链：  
  1. 信息抽取链：原始文本 → 抽取 prompt → 本地小模型 → JSON → 存库。  
  2. RAG 问答链：问题 → 检索（向量 + 元数据过滤）→ QA prompt → LLM。  
  3. 多人场景建议链：问题 + 多人画像 + 片段 → 场景 prompt → LLM。  
  4. 人物画像链：聚合某人历史记录 → 摘要 prompt → 画像文本。  

- 提示词原则：  
  - 明确“只能基于给定片段，不要幻想”。  
  - 输出结构尽量固定（JSON 或分段标题），方便解析和前端展示。  

- 实现方式建议：  
  - 采用 LangChain 组织 prompts 与 LLM 调用。  
  - 使用 PydanticOutputParser 或 JSON 输出模式提高鲁棒性。

### 5.3 模型与设备策略（Qwen 优先）

- 桌面端：  
  - 本地大模型：推荐 Qwen 系列，如 Qwen2-7B（推理主力），可根据显存选择 Qwen2-7B/32B 等更大模型。  
  - 本地 embedding 模型：如 384 维句向量模型（Sentence-Transformers 系），可运行在 CPU。  
  - 微调：使用 LoRA/QLoRA 对 Qwen2-1.5B / Qwen2-3B 等小模型微调，让其更懂用户圈子、关系场景。  

- 手机端（未来）：  
  - 极轻量模式：约 1B 模型（4bit 量化），可选 Qwen 小型变体，用于信息抽取和简单问答。  
  - 高配模式：2–3B 模型（4bit 量化），适合 iPhone 13 Pro / Pro Max 及高端安卓。  
  - 复杂多人的推理场景：调用家用电脑（Qwen2-7B）/云端大模型。

### 5.4 向量与性能

- 向量存储  
  - 所有向量存于本地向量库文件（磁盘），而非常驻内存。  
  - 通过文档 id 与 SQLite 中的 Event 记录关联。  

- 规模预期  
  - 千级 Person，万级 Event 为主要目标；即使十万级 Event，向量占用也在百 MB 级别以内。  

- 检索性能  
  - 每次查询：一次问题向量化 + 在候选集中的相似度检索。  
  - 通过 person/time/tag 过滤缩小候选集，保证检索毫秒级。  
  - 相比 LLM 推理，RAG 检索算力消耗可以忽略不计。

### 5.5 调优与训练策略（端到端）

- 本地小模型微调（强烈推荐）  
  - 数据来源：  
    - 用户输入的事实与事件记录（Person/Event/子表）。  
    - 用户对系统回答的反馈（准确/不准/有风险等打分）。  
  - 任务类型：  
    - 情绪/偏好分类（如“喜欢/中立/讨厌某种礼物”、“情绪偏正向/负向”）。  
    - 关系风险判定（如“A 和 C 适合同桌吗？”、“是否适合现在谈敏感话题？”）。  
    - 风格对齐（让回答更像用户、用用户习惯的话语风格）。  
  - 技术栈：  
    - Hugging Face Transformers + PEFT（LoRA/QLoRA）+ bitsandbytes 等轻量训练方案。  
    - 目标模型：1–3B 量级中文友好模型（Qwen2-1.5B、Qwen2-3B 等），在本地 GPU 或可选云 GPU 上训练。  

- 远端大模型作为“教师模型”  
  - 在用户同意前提下，选取少量脱敏样本（三元组）：  
    - 问题（用户真实问题或模拟问题）。  
    - 本地事实（相关事件的摘要/结构化信息，而非原始全量文本）。  
    - 模型现有回答。  
  - 将问题 + 本地事实发送给远端大模型，请其给出“理想答案”。  
  - 将（问题，理想答案，本地事实）存为训练样本，用于反复微调本地小模型。  
  - 远端模型定位为“离线老师”：  
    - 只在训练样本生成阶段使用，而不是每次都在线推理。  
    - 目标是逐步提高本地小模型的推理/表达能力，减少对远端依赖。  

- 端到端学习闭环  
  1. 数据摄入：用户通过手动/截图/语音录入事实 → 抽取 → 入库。  
  2. 在线使用：用户发问 → 本地 RAG + 小/大模型回答。  
  3. 反馈记录：用户对回答质量打分，标记“准/不准/有风险”。  
  4. 样本构建：将问题、事实片段、用户反馈、（可选）教师模型答案整理成训练样本。  
  5. 周期训练：定期在本地或信任的 GPU 环境运行 LoRA/QLoRA 训练任务，更新本地小模型权重。  
  6. 部署更新：新版本小模型替换运行时模型，进入下一轮循环。  

- 边界与安全  
  - 默认训练仅使用本地数据，不上传至云端；如需使用远端教师模型，须在 UI/配置中显式开启。  
  - 训练样本中对人物标识、敏感内容做脱敏处理（如用代号替代姓名）。  
  - 提供简单开关：用户可以关闭训练与数据收集，仅保留在线推理能力。

### 5.6 安全、加密与评估

- 数据加密与存储  
  - SQLite 层：优先考虑使用 SQLCipher 或等价方案对整个数据库文件加密；或在应用层对敏感字段（raw_text 等）单独加密。  
  - 密钥管理：加密密钥存于系统安全机制（OS Keychain、系统凭证存储），不写入明文配置文件。  
  - 备份：提供加密备份/恢复功能，备份文件同样采用对称加密。  

- 访问控制与本地安全  
  - 应用启动时可选启用“主密码”或操作系统账号验证。  
  - 桌面/手机端界面支持自动锁定（空闲一段时间后需要解锁）。  

- 评估与监控  
  - 构建一小份“典型问答验证集”（例如：送礼、聚餐、冲突场景），用于离线评估不同模型版本的表现。  
  - 记录简单统计：回答被标记为“准确/一般/不准”的比例、平均响应时间、RAG 命中率（是否找到足够片段）。  
  - 日志中避免写入完整版敏感内容，只记录必要的元数据和脱敏摘要。  

- Schema 迁移策略  
  - 为 SQLite schema 定义版本号（如 `schema_version` 表）。  
  - 采用简单迁移脚本或 Alembic（如迁移工具）维护升级路径，确保随着功能扩展，老数据仍然可用。  

- LLM 抽象与可替换性  
  - 在 `backend/llm` 中保持统一接口，使得 Qwen、本地其它模型、远端 GPT 类模型可以随时替换或并行存在。  
  - 通过配置文件（`config/settings.toml`）选择当前使用的模型组合与运行模式（本地/混合/云增强）。

---

## 6. 代码与文件结构

目标：先开发电脑端本地后端 + Web/CLI 界面，代码结构为未来接入 iOS/Android 做准备。

### 6.1 顶层结构

```text
.
  prd.md                      # 本 PRD 文档
  README.md                   # 项目说明（对用户/开发者）
  requirements.txt            # Python 依赖列表（后续填充）

  config/
    settings.toml             # 全局配置（路径、模式、本地/混合模式等）
    prompts/
      extract_event.txt       # 信息抽取 prompt 模板
      qa_rag.txt              # RAG 问答 prompt 模板
      scene_advice.txt        # 多人场景建议 prompt 模板
      person_summary.txt      # 人物画像 prompt 模板

  backend/
    core/
      __init__.py
      db.py                   # SQLite 连接 & schema 初始化
      models.py               # Pydantic/数据模型定义
      repositories.py         # Person/Event/Relationship CRUD
      ingest.py               # ingest_manual/ingest_ocr/ingest_audio
      reminders.py            # 提醒任务逻辑
    rag/
      __init__.py
      embeddings.py           # 文本向量化封装
      vector_store.py         # 向量库封装（Chroma/FAISS）
      retriever.py            # 带元数据过滤的检索器
      chains.py               # RAG/场景/画像等 LangChain 链
    llm/
      __init__.py
      local_client.py         # 本地小/大模型客户端
      remote_client.py        # 远端大模型客户端
      prompts.py              # Prompt 加载与管理
    api/
      __init__.py
      service.py              # 对前端/CLI 暴露的统一服务接口（可接 FastAPI）

  mcp_server/
    __init__.py
    server.py                 # MCP server 主程序
    tools/
      __init__.py
      search_events.py        # 提供 RAG 检索工具
      get_person_summary.py   # 提供人物画像摘要工具
      log_feedback.py         # 记录用户反馈工具

  frontend/
    cli/
      __init__.py
      main.py                 # CLI 入口（添加记录、提问、查看提醒）
    web/
      __init__.py
      app.py                  # Web 应用入口（“一人一本笔记本”界面）

  scripts/
    init_db.py                # 初始化数据库
    import_sample_data.py     # 导入样例数据
    run_reminders.py          # 定时执行提醒扫描
```

---

## 7. 开发计划（迭代路线）

### 7.1 阶段 v0.1：本地底座 & 最小可用（约 1–2 周）

- 实现 SQLite schema 和基本 CRUD：Person / Event / Relationship。  
- 完成 `backend/core/db.py`、`models.py`、`repositories.py`。  
- 实现 `ingest_manual`：手动文本录入 → 信息抽取链（可先用 mock 或远端模型）→ 入库。  
- 接入本地 embedding + 向量库，实现最小 RAG 检索和问答链（可用 mock LLM）。  
- 提供简单 CLI：  
  - 添加朋友、添加事件、按人 + 时间查看事件列表。  
  - 提问一个简单问题并看到 RAG 回答。

### 7.2 阶段 v0.2：电脑端体验完善 & 多输入（约 1–2 周）

- 补全 ingest 链：  
  - `ingest_ocr`：截图 → OCR → 文本 → 抽取 → 入库。  
  - `ingest_audio`：语音 → Whisper → 文本 → 抽取 → 入库。  
- 实现“一人一本笔记本” Web 界面：  
  - 左侧朋友列表，中央时间线 + 标签过滤，右侧 AI 问答栏。  
- 完善提醒机制：生日、长时间未联系、情绪波动提醒。  
- 引入反馈机制：用户对回答打分，存入反馈表。

### 7.3 阶段 v0.3：MCP + 远端增强 + 微调（后续）

- 实现本地 MCP server：  
  - 暴露 `search_events`、`get_person_summary`、`log_feedback` 等工具。  
  - 接入远端大模型，使其能够在复杂场景下调用本地工具进行推理。  
- 收集高质量问答样本，启动本地小模型 LoRA/QLoRA 微调：  
  - 专注情绪、关系、场景化建议的能力。  
- 优化 RAG：  
  - 更细的元数据过滤策略。  
  - top_k、向量维度、分片策略调优。

### 7.4 阶段 v0.4+：图谱可视化 & 移动端探索

- 使用 NetworkX 构建关系图谱，并在 Web 前端可视化。  
- 设计手机端 App 原型：  
  - 与本地/家用服务器后端的 API 通信。  
  - 探索在 iOS/Android 端运行 1B/3B 小模型的方案。  
- 增加更多场景化玩法：旅行规划、长期关系策略等。

---

## 8. 未来拓展方向

- 更复杂的多好友布阵：3–5 人聚会的座位/话题安排、旅行队伍组合优化。  
- 关系分层与关键节点识别：  
  - 通过图算法识别“最值得维护的关系”和“隐藏关键人物”。  
- 知识图谱化：  
  - 将人、偏好、情绪、事件抽象为图谱，提高推理可解释性。  
- 手机离线完整体验：  
  - 手机端独立完成录入、抽取、查询、简单建议。  
- 教师-学生训练闭环：  
  - 远端大模型输出高质量答案 → 存为训练数据 → 周期性微调本地模型，逐步减少对远端依赖。

