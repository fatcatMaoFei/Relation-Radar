#!/usr/bin/env python3
"""
Test script for PR-0.1-05: Embedding pipeline & vector store
"""
from __future__ import annotations

import sys
from pathlib import Path

# Ensure project root is on sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from backend.rag.embeddings import get_embedding_client  # noqa: E402
from backend.rag.vector_store import get_vector_store  # noqa: E402


def test_embedding_pipeline():
    """Test the complete embedding pipeline."""
    print("ğŸš€ Testing Embedding Pipeline...")
    
    # Initialize clients
    embedding_client = get_embedding_client()
    vector_store = get_vector_store()
    
    # Clear any existing data
    vector_store.clear()
    print(f"ğŸ“Š Vector store initialized. Count: {vector_store.count()}")
    
    # Test data - sample relation events
    test_documents = [
        "çŒ«ä»Šå¤©å¿ƒæƒ…å¾ˆå¥½ï¼Œæˆ‘ä»¬ä¸€èµ·å»åƒäº†å·èœï¼Œå¥¹å¾ˆå–œæ¬¢éº»è¾£çš„å‘³é“",
        "é˜¿Bæ˜¨å¤©å¥èº«å¾ˆç´¯ï¼Œä¸è¿‡ä»–è¯´æ„Ÿè§‰å¾ˆæœ‰æˆå°±æ„Ÿï¼Œä¸‹æ¬¡è¿˜æƒ³ä¸€èµ·å»",
        "å°å¼ ç”Ÿæ—¥å¿«åˆ°äº†ï¼Œå¥¹å¹³æ—¶å–œæ¬¢å®‰é™çš„ç¯å¢ƒï¼Œä¸å¤ªå–œæ¬¢å¤ªçƒ­é—¹çš„åœ°æ–¹",
        "å’ŒçŒ«èŠå¤©æ—¶å‘ç°å¥¹æœ€è¿‘å‹åŠ›æœ‰ç‚¹å¤§ï¼Œå·¥ä½œä¸Šçš„äº‹æƒ…è®©å¥¹æœ‰äº›ç„¦è™‘",
        "é˜¿Bæ¨èäº†ä¸€å®¶æ–°çš„å¥èº«æˆ¿ï¼Œè®¾å¤‡å¾ˆå¥½ï¼Œç¯å¢ƒä¹Ÿä¸é”™"
    ]
    
    print("\nğŸ“ Test Documents:")
    for i, doc in enumerate(test_documents, 1):
        print(f"  {i}. {doc}")
    
    # Test 1: Single text embedding
    print("\nğŸ”§ Test 1: Single Text Embedding")
    test_text = test_documents[0]
    vector = embedding_client.encode(test_text)
    print(f"Text: {test_text}")
    print(f"Vector dimension: {len(vector)}")
    print(f"Vector (first 5): {vector[:5]}")
    
    # Test 2: Batch embedding
    print("\nğŸ”§ Test 2: Batch Text Embedding")
    vectors = embedding_client.encode_batch(test_documents)
    print(f"Batch size: {len(test_documents)}")
    print(f"Vector matrix shape: {vectors.shape}")
    
    # Test 3: Add documents to vector store
    print("\nğŸ”§ Test 3: Adding Documents to Vector Store")
    doc_ids = [f"doc_{i}" for i in range(len(test_documents))]
    metadatas = [
        {"person": "çŒ«", "type": "èšé¤", "emotion": "å¼€å¿ƒ"},
        {"person": "é˜¿B", "type": "å¥èº«", "emotion": "æ»¡è¶³"},
        {"person": "å°å¼ ", "type": "ç”Ÿæ—¥", "emotion": "ä¸­æ€§"},
        {"person": "çŒ«", "type": "èŠå¤©", "emotion": "ç„¦è™‘"},
        {"person": "é˜¿B", "type": "æ¨è", "emotion": "ç§¯æ"}
    ]
    
    added_ids = vector_store.add_documents(
        texts=test_documents,
        ids=doc_ids,
        metadatas=metadatas
    )
    print(f"Added {len(added_ids)} documents")
    print(f"Vector store count: {vector_store.count()}")
    
    # Test 4: Text similarity search
    print("\nğŸ”§ Test 4: Similarity Search")
    query_text = "çŒ«çš„å¿ƒæƒ…æ€ä¹ˆæ ·ï¼Ÿ"
    print(f"Query: {query_text}")
    
    ids, distances, metadatas = vector_store.search_by_text(
        query_text=query_text,
        top_k=3
    )
    
    print("Top 3 similar documents:")
    for i, (doc_id, distance, metadata) in enumerate(zip(ids, distances, metadatas)):
        doc_data = vector_store.get_by_id(doc_id)
        document = doc_data['document'] if doc_data else "Not found"
        print(f"  {i+1}. ID: {doc_id}")
        print(f"     Distance: {distance:.4f}")
        print(f"     Metadata: {metadata}")
        print(f"     Text: {document}")
        print()
    
    # Test 5: Vector similarity search
    print("ğŸ”§ Test 5: Vector-based Search")
    query_vector = embedding_client.encode("å¥èº«ç›¸å…³çš„å†…å®¹")
    ids, distances, metadatas = vector_store.search(
        query_vector=query_vector,
        top_k=2
    )
    
    print("Query: å¥èº«ç›¸å…³çš„å†…å®¹")
    print("Top 2 similar documents:")
    for i, (doc_id, distance, metadata) in enumerate(zip(ids, distances, metadatas)):
        doc_data = vector_store.get_by_id(doc_id)
        document = doc_data['document'] if doc_data else "Not found"
        print(f"  {i+1}. ID: {doc_id}, Distance: {distance:.4f}")
        print(f"     Text: {document}")
        print()
    
    # Test 6: Text similarity calculation
    print("ğŸ”§ Test 6: Text Similarity")
    text1 = "çŒ«å¿ƒæƒ…å¾ˆå¥½"
    text2 = "çŒ«ä»Šå¤©å¾ˆå¼€å¿ƒ"
    text3 = "é˜¿Båœ¨å¥èº«"
    
    sim_score = embedding_client.similarity(text1, text2)
    print(f"Similarity between '{text1}' and '{text2}': {sim_score:.4f}")
    
    sim_score = embedding_client.similarity(text1, text3)
    print(f"Similarity between '{text1}' and '{text3}': {sim_score:.4f}")
    
    # Test 7: Metadata filtering
    print("\nğŸ”§ Test 7: Metadata Filtering")
    ids, distances, metadatas = vector_store.search_by_text(
        query_text="å¿ƒæƒ…",
        top_k=5,
        where={"person": "çŒ«"}
    )
    
    print("Query: 'å¿ƒæƒ…' filtered by person='çŒ«'")
    print(f"Found {len(ids)} documents:")
    for i, (doc_id, distance, metadata) in enumerate(zip(ids, distances, metadatas)):
        doc_data = vector_store.get_by_id(doc_id)
        document = doc_data['document'] if doc_data else "Not found"
        print(f"  {i+1}. {document}")
    
    print("\nâœ… All tests completed successfully!")
    print(f"ğŸ“Š Final vector store count: {vector_store.count()}")
    
    return True


if __name__ == "__main__":
    try:
        test_embedding_pipeline()
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        sys.exit(1)
